import requests
from bs4 import BeautifulSoup
import pandas as pd

# Function to extract product information from a single product listing
def extract_product_info(product):
    name = product.find('span', class_='a-size-medium').get_text(strip=True)
    price = product.find('span', class_='a-price-whole').get_text(strip=True) if product.find('span', class_='a-price-whole') else 'N/A'
    rating = product.find('span', class_='a-icon-alt').get_text(strip=True) if product.find('span', class_='a-icon-alt') else 'N/A'
    return name, price, rating

# Function to scrape the given URL and return product information
def scrape_products(url):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, 'html.parser')

    products = soup.find_all('div', class_='s-result-item')

    product_data = []
    for product in products:
        name, price, rating = extract_product_info(product)
        product_data.append({
            'Name': name,
            'Price': price,
            'Rating': rating
        })

    return product_data

# Function to save the scraped data to a CSV file
def save_to_csv(product_data, filename):
    df = pd.DataFrame(product_data)
    df.to_csv(filename, index=False)
    print(f'Data saved to {filename}')

def main():
    url = 'https://www.amazon.com/s?k=laptops'  # Example URL for the Amazon laptops category
    product_data = scrape_products(url)
    save_to_csv(product_data, 'products.csv')

if __name__ == '__main__':
    main()
